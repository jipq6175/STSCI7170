---
title: "STSCI 7170 Homework 2"
author: "Yen-Lin Chen (yc2253@cornell.edu)"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Problem 1

Suppose that rank$(A)=a$ and $B \in \mathbb{R}^{m\times n}$. We can write the quadratic form $Y'AY = Z'DZ$ where $Z = P'\Sigma^{-\frac{1}{2}}Y \sim N_n(P'\Sigma^{-\frac{1}{2}}\mu, I_n)$ and $\Sigma^{\frac{1}{2}}A\Sigma^{\frac{1}{2}} = PDP'$ by spectral decomposition. $D$ is a diagonal with $d_{ii} \neq 0 \quad \forall i \in \{1,2,\dots,a\}$. 

Moreover, $BY = B\Sigma^{\frac{1}{2}}PZ = MZ$ where $M =  B\Sigma^{\frac{1}{2}}P$.

$$A\Sigma B' = 0 \iff B\Sigma A=0\\ \iff B\Sigma^{\frac{1}{2}}\Sigma^{\frac{1}{2}}A\Sigma^{\frac{1}{2}} = 0 \\ \iff B\Sigma^{\frac{1}{2}}PDP' = 0 \\ \iff MD = 0$$
$$D = \begin{bmatrix}
D_a & 0 \\
0 & 0
\end{bmatrix}; \quad M = \begin{bmatrix}
M_1 & M_2 \end{bmatrix},
$$
where $M_1 \in \mathbb{R}^{m\times a}$ and $M_2 \in \mathbb{R}^{m \times (n-a)}$
$$MD = 0 \iff M_1D_a =0 \iff M_1 = 0 \iff M = \begin{bmatrix}
0 & M_2 \end{bmatrix}$$
$$Y'AY = \sum_{j=1}^a\lambda_jz_j^2; \quad (BY)_i = \sum_{j=n-a+1}^nm_{ij}z_j$$
Because $z_i$'s are independent, $Y'AY$ and $BY$ are independent. 

## Problem 2

Suppose the positive semi-definite symmetric matrix $A$ has rank $a$, then $A$ has $a$ non-zero eigenvalues $\lambda_1, \lambda_2, \dots, \lambda_a > 0$ and $\lambda_i = 0$ $\forall i \in \{a+1, \dots, n\}$. We can write the spectra decomposition of $A$ as $A = PDP'$ where the columns of $P$ are $a$ orthonormal vectors: $P = (p_1, p_2, \dots, p_n) \in \mathbb{R}^{n\times n}$. Therefore, 
$$A = \sum_{k=1}^n \lambda_kp_kp_k' = \sum_{k=1}^a \lambda_kp_kp_k'$$
Or equivalently, 
$$a_{ij} = \sum_{k=1}^n\lambda_kp_{ki}p_{kj} = \sum_{k=1}^a\lambda_kp_{ki}p_{kj}$$
where $p_{ki}$ is the $i$\textsuperscript{th} element of the $k$\textsuperscript{th} columns of $P$.

### 2a

$$a_{ii} = \sum_{k=1}^n\lambda_kp_{ki}^2 \geq 0$$
because $\lambda_k \geq 0$. 

### 2b

If
$$a_{ii} = \sum_{k=1}^n\lambda_kp_{ki}^2 = \sum_{k=1}^a\lambda_kp_{ki}^2 = 0 $$
Because $\lambda_k > 0 \quad \forall k=1,2,\dots, a$, $p_{ki} = 0 \quad \forall k=1,2,\dots, a$. 
$$\forall i\neq j \quad a_{ij} = \sum_{k=1}^a\lambda_kp_{ki}p_{kj} = 0$$


## Problem 3





## Moser 2.5

Let $\mu = (\mu_1, \mu_2, \dots, \mu_A)'$ and since $Y_{ijk} = \mu_i + S_{ij} + T_{ijk}$ we can write 

$$Y = (\mu \otimes 1_s \otimes 1_t) + (I_a \otimes I_s \otimes 1_t)S + (I_a \otimes I_s \otimes I_t)T$$
where $S \sim N_{as}(0_{as}, \sigma_S^2I_{as})$ and $T \sim N_{ast}(0_{ast}, \sigma_T^2I_{ast})$. Therefore, we have the following. 

$$E[Y] = \mu \otimes 1_s \otimes1_t$$

$$\Sigma = (I_a \otimes I_s \otimes 1_t)\sigma_S^2I_{as}(I_a \otimes I_s \otimes 1'_t) + (I_a \otimes I_s \otimes I_t)\sigma_T^2I_{ast}(I_a \otimes I_s \otimes I_t)$$ 
$$\Sigma = \sigma_S^2(I_a \otimes I_s \otimes 1_t1'_t) + \sigma_T^2I_{ast}$$

### a

$\bar{Y}_i = (\bar{Y}_{1..}, \bar{Y}_{2..}, \dots, \bar{Y}_{a..})' = MY$ where $M = I_a \otimes(\frac{1}{s}1'_s) \otimes (\frac{1}{t}1'_t) = \frac{1}{st} I_a \otimes 1'_s \otimes 1'_t$. Therefore, $\bar{Y}_i \sim N_a(\mu, M\Sigma M')$.

$$M\Sigma M' = \frac{\sigma_S^2}{s^2t^2}(I_a \otimes1'_s1_s \otimes1'_t1_t) + \frac{\sigma_T^2}{s^2t^2}(I_a \otimes1'_s1_s \otimes1'_t1_t)$$
$$M\Sigma M' = \left(\frac{\sigma_S^2 + \sigma_T^2}{st} \right)I_a$$


### b
$(\bar{Y}_{11.}-\bar{Y}_{1..}, \dots, \bar{Y}_{1s.}-\bar{Y}_{1..}, \dots, \bar{Y}_{a1.}-\bar{Y}_{a..}, \dots, \bar{Y}_{as.}-\bar{Y}_{a.}) = KY \in \mathbb{R}^{as}$ where 

$$KY = \left(I_a \otimes I_s \otimes\frac{1}{t}1'_t \right)Y - \left(I_a \otimes \frac{1}{s}1_s1'_s \otimes \frac{1}{t}1'_t \right)Y = \left(I_a \otimes C_s \otimes \frac{1}{t}1'_t\right)Y$$
Therefore, $KY \sim N_{as}(KE[Y], K\Sigma K')$

$$KE[Y] = K(\mu \otimes 1_s \otimes 1_t) = 0_{as}$$

$$K\Sigma K' = \sigma_S^2 \left( I_a \otimes C_sI_sC_s \otimes\frac{1}{t^2}1'_t1_t1'_t1_t \right) + \sigma_T^2 \left(I_a \otimes C_sI_sC_s\otimes\frac{1}{t^2}1'_t1_t \right)$$
$$K\Sigma K' = \left(\sigma_S^2 + \frac{\sigma_T^2}{t} \right)(I_a \otimes C_s)$$



## Moser 2.10

We have $Y=X\beta+E$ where $\beta$ is an unknown constant vector and $E\sim N_n(0_n, \sigma^2I_n)$. The only randomness comes from the vector $E$. 

### a

$$\hat{\beta} = (X'X)^{-1}X'Y = (X'X)^{-1}X'(X\beta + E) = \beta + (X'X)^{-1}X'E = \beta + ME$$
where $M = (X'X)^{-1}X'$. Therefore, since $E$ is normal, we have $\hat{\beta} \sim N_p(\beta, \sigma^2MM')$. Because $(X'X)^{-1}$ exists, $X'X$ must be non-singular, i.e. rank$(X'X) = p$ and $p < n$. Moreover, $(X'X)^{-1}$ is symmetric.  

$$MM' = (X'X)^{-1}X'X\left((X'X)^{-1} \right)' = (X'X)^{-1}$$
$$\hat{\beta} \sim N_p\left(\beta, \sigma^2(X'X)^{-1} \right)$$


### b

We can do singular value decomposition (SVD) of $X$, i.e. $X = U\Sigma V'$ where $U \in \mathbb{R}^{n\times n}$ and $V \in \mathbb{R}^{p\times p}$ with $U'U = I_n$ and $V'V = I_p$. $\Sigma \in \mathbb{R}^{n\times p}$ and since we know that $p < n$, 

$$\Sigma = \begin{bmatrix} \Sigma_1\\ 0 \end{bmatrix}$$
where $\Sigma_1$ is $p \times p$ diagonal matrix. $X'X = V\Sigma'\Sigma V' = V \Sigma_1^2V'$ is nonsingular if and only if all the diagonal elements of $\Sigma_1$ are nonzero. Additionally, $(X'X)^{-1} = V \Sigma_1^{-2}V'$ 

Therefore, 

$$\text{Cov}(X\hat{\beta}) = \sigma^2X(X'X)^{-1}X' = \sigma^2U\begin{bmatrix}
\Sigma_1 \\
0 \end{bmatrix}V'V\Sigma_1^{-2} V'V \begin{bmatrix} \Sigma_1 & 0 \end{bmatrix}U'$$

$$\text{Cov}(X\hat{\beta}) = \sigma^2 U \begin{bmatrix} 
I_p & 0 \\
0 & 0_{n-p} \end{bmatrix} U'$$

As a result, $\text{rank}(\text{Cov}(\hat{Y})) = \text{rank}(\text{Cov}(X\hat{\beta})) = p$

## Moser 3.3

Construct the A-matrices as the following. 

$$A_1 = \bar{J}_a \otimes \bar{J}_s \otimes \bar{J}_t \quad \text{rank}(A_1) = n_1 = 1$$

$$A_2 = C_a \otimes \bar{J}_s \otimes \bar{J}_t \quad \text{rank}(A_2) = n_2 = a-1$$
$$A_3 = \bar{J}_a \otimes C_s \otimes \bar{J}_t \quad \text{rank}(A_3) = n_3 = s-1$$

$$A_4 = C_a \otimes C_s \otimes \bar{J}_t \quad \text{rank}(A_4) = n_4 = (a-1)(s-1) = as -a-s+1$$

$$A_5 = I_a \otimes I_s \otimes C_t \quad \text{rank}(A_5) = n_5 = as(t-1) = ast-as$$

And the assumptions of Bhat's lemma are satisfied: $\sum_{i=1}^5 A_i = I_{ast}$ and $\sum_{i=1}^5n_i=ast$.

Previously, in Moser 2.5, we have 

$$\text{Cov}(Y) = \Sigma = t\sigma_S^2(I_a \otimes I_s \otimes \bar{J}_t) + \sigma_T^2I_{ast}$$

$$\Sigma = (t\sigma_S^2 + \sigma_T^2)\sum_{i=1}^4A_i + \sigma_T^2A_5$$


### a

$$V_1 = Y'(I_a \otimes C_s \otimes \bar{J}_t) Y = Y'(A_3+A_4)Y$$

As a result, $Y'(A_3+A_4)Y \sim (t\sigma_S^2 + \sigma_T^2)\chi^2_{a(s-1)}(\delta_1)$ where 

$$\delta_1 = (t\sigma_S^2 + \sigma_T^2)^{-1}(\mu \otimes 1_s \otimes 1_t)'(I_a\otimes C_s \otimes \bar{J}_t)(\mu \otimes 1_s \otimes 1_t) = 0$$

$$V_1 \sim (t\sigma_S^2 + \sigma_T^2)\chi^2_{a(s-1)}(0)$$

### b
$$V_2 = Y'(I_a \otimes I_s \otimes C_t)Y = Y'A_5Y$$
So, $Y'A_5Y \sim \sigma_T^2\chi^2_{as(t-1)}(\delta_2)$ where

$$\delta_2 = \sigma_T^{-2}(\mu \otimes 1_s \otimes 1_t)'(I_a\otimes I_s \otimes C_t)(\mu \otimes 1_s \otimes 1_t) = 0$$

$$V_2 \sim \sigma_T^2\chi^2_{as(t-1)}(0)$$


### c

Combining $V_1$ and $V_2$, we have the following directly. 

$$\frac{V_1/[a(s-1)]}{V_2/[as(t-1)]} \sim \frac{t\sigma_S^2 + \sigma_T^2}{\sigma_T^2} F_{a(s-1), as(t-1)}(0)$$


## Moser 3.15

### a

With one $i$ fixed, and $y_i = (Y_{i1}, Y_{i2})'$ we have the following.

$$\text{E}(y_i) = \begin{bmatrix} \mu_1 & \mu_2 \end{bmatrix}' $$

$$\mu = 1_n \otimes \begin{bmatrix} 
\mu_1 \\
\mu_2 \end{bmatrix}$$


$$\text{Cov}(y_i) = \sigma^2\begin{bmatrix}
1 & \rho \\
\rho & 1 \end{bmatrix} = \sigma^2\left[(1+2\rho)I_2 - 2\rho C_2 \right]$$ 

Therefore, $\Sigma = I_n \otimes \text{Cov}(y) = \sigma^2\left[ (1+2\rho)(I_n \otimes I_n) -2\rho(I_n\otimes C_2) \right]$


### b

Let $y = (Y_{i1}, Y_{i2})'$ and we can write $D_i = Y_{i1}-Y_{i2} = My_i$ where $M = \begin{bmatrix} 1 & -1 \end{bmatrix}'$. The distribution of $D-i$ can be found: $D_i \sim N(\mu_2-\mu_1, M\text{Cov}(y_i)M')$, where

$$M\text{Cov}(y_i)M' = \sigma^2 M\begin{bmatrix}
1 & \rho \\
\rho & 1 \end{bmatrix}M' = 2\sigma^2(1-\rho)$$

Therefore, $D = (D_1, D_2, \dots, D_n)'$ is a random vector $D \sim N_n((\mu_2-\mu_1)1_n, 2\sigma^2(1-\rho)I_n)$.

$$\bar{D} = \frac{1}{n}1'_nD \sim N\left( \mu_2-\mu_1, \frac{2}{n}\sigma^2(1-\rho) \right)$$

$$\sum_{i=1}^n (D_i - \bar{D})^2 = (n-1)S_D^2 = D'C_nD \sim 2\sigma^2(1-\rho)\chi_{n-1}^2(0)$$
By using the definition of t-distribution, 

$$\frac{\bar{D}/\sqrt{\frac{1}{n}2\sigma^2(1-\rho)}}{\sqrt{\frac{1}{2\sigma^2(1-\rho)}\frac{1}{n-1}\sum_{i=1}^n(D_i-\bar{D})^2}} = \frac{\bar{D}}{\left(\frac{S_D}{\sqrt{n}} \right)} \sim T_{n-1}(\mu_2-\mu_1)$$

## Moser 3.17

### a

Let $\sigma_1 = \sigma_2 = \sigma$. From the corvariance matrix, $\Sigma$, $Y_{ij}$'s are independent. $\bar{Y}_{1.} \sim N(\mu_1, \sigma^2/n_1)$ and $\bar{Y}_{2.} \sim N(\mu_2, \sigma^2/n_2)$. Therefore, 

$$\bar{Y}_{1.} - \bar{Y}_{2.} \sim N \left( \mu_2-\mu_1, \sigma^2\left(\frac{1}{n_1}+\frac{1}{n_2} \right)\right)$$
Moreover, the term in the denominator can be separated into two: 

$$i=1 \quad S_1^2 = \sum_{j=1}^{n_1}(Y_{1j}-\bar{Y}_{1.})^2 \sim \sigma^2\chi_{n_1-1}^2(0)$$

$$i=2 \quad S_2^2 = \sum_{j=1}^{n_2}(Y_{2j}-\bar{Y}_{2.})^2 \sim \sigma^2\chi_{n_2-1}^2(0)$$

Since $S_1^2$ and $S_2^2$ are independent, $S_1^2 + S_2^2 \sim \chi_{n_1+n_2-2}^2(0)$

According to the definition of F-distribution, we can write

$$\frac{(\bar{Y}_{1.} - \bar{Y}_{2.})^2/ \sigma^2(\frac{1}{n_1}+\frac{1}{n_2})}{\frac{1}{\sigma^2}(S_1^2+S_2^2)/(n_1+n_2-2)} = \frac{(\bar{Y}_{1.} - \bar{Y}_{2.})^2/ (\frac{1}{n_1}+\frac{1}{n_2})}{(S_1^2+S_2^2)/(n_1+n_2-2)} = V \sim F_{1, n_1+n_2-2}(\mu_1-\mu_2)$$


### b





## Moser 4.5

The model for the problem is 

$$Y_{ij} = \mu_j + B_{i} + (BT)_{ij} \quad \text{i.e.} \quad Y = (1_n\otimes\mu) + (I_n\otimes1_2)\tilde{B} + (I_n \otimes I_2)\tilde{BT}$$

where $\tilde{B} \sim N_n(0, \sigma_B^2I_n) \in \mathbb{R}^n$ and $\tilde{BT} \sim N_{2n}(0, \sigma_{BT}^2I_{2n}) \in \mathbb{R}^{2n}$ are the random vectors corresponding to $B$ and $BT$. The $\mu$ here is $(\mu_1, \mu_2)'$, representing the $j$\textsuperscript{th} level of fixed factors. 

### a

$$E[Y] = 1_n\otimes\mu $$


$$\Sigma = \text{Cov}(Y) = (I_n\otimes1_2)(\sigma_B^2I_n)(I_n\otimes 1'_2) + (I_n\otimes I_2)(\sigma_{BT}^2I_{2n})(I_n\otimes I_2) \\ 
=\frac{1}{2}\sigma_B^2(I_n \otimes \bar{J}_2)+\sigma_{BT}^2(I_n\otimes I_2)$$


### b

The ANOVA table is shown in Table 1. 

\begin{table}[]
\caption{The ANOVA table for Moser 4.5.(b) and (c). $\delta_1$ and $\delta_2$ can be found in the main text.}
\centering
\begin{tabular}{ccccc}
Name & Formula &$A_i$ & rank & $Y'A_iY$ Dist.\\
\hline
 &$\sum_i\sum_j(\bar{Y}_{..})^2 $ &$A_1 = \bar{J}_n\otimes\bar{J}_2$ &  $1$ & $\left(\frac{\sigma_B^2}{2}+\sigma_{BT}^2 \right)\chi_1^2(\delta_1)$ \\
 &$\sum_i\sum_j(\bar{Y}_{i.} - \bar{Y}_{..})^2 $ &$A_2 = C_n\otimes\bar{J}_2$ & $n-1$ & $\left(\frac{\sigma_B^2}{2}+\sigma_{BT}^2 \right)\chi_{n-1}^2(0)$  \\
 &$\sum_i\sum_j(\bar{Y}_{.j} - \bar{Y}_{..})^2 $ &$A_3 = \bar{J}_n\otimes C_2$ & $1$ & $\sigma_{BT}^2 \chi_{1}^2(\delta_3)$   \\
 &$\sum_i\sum_j(Y_{ij} - \bar{Y}_{i.} - \bar{Y}_{.j} + \bar{Y}_{..})^2 $ &$A_4 = C_n \otimes C_2$ & $n-1$ & $\sigma_{BT}^2 \chi_{n-1}^2(0)$  \\
\hline
 &$\sum_i\sum_j(Y_{ij})^2 $ &$A_5 = I_n \otimes I_2$ & $2n$ & N/A
\end{tabular}
\end{table}


### c

In order to determine the distribution of $Y'A_iY$, we need to apply Bhat's lemma.

$$\Sigma =\frac{1}{2}\sigma_B^2(I_n \otimes \bar{J}_2)+\sigma_{BT}^2(I_n\otimes I_2) = \left(\frac{\sigma_B^2}{2}+\sigma_{BT}^2 \right)(A_1 + A_2) + \sigma_{BT}^2(A_3+A_4)$$
All the $A_i$-matrices satisfy the assumption of Bhat's lemma $\forall i=1,2,3,4$. 

$$Y'A_iY \sim c_i\chi^2_{\text{rank}(A_i)}(\delta_i) \quad \text{where} \quad \delta_i = \frac{1}{c_i}\mu'A_i\mu$$

$$Y'A_1Y \sim \left(\frac{\sigma_B^2}{2}+\sigma_{BT}^2 \right)\chi_1^2(\delta_1) \quad \delta_1 = \frac{n(\mu_1+\mu_2)^2}{\sigma_B^2 + 2\sigma_{BT}^2}$$

$$Y'A_2Y \sim \left(\frac{\sigma_B^2}{2}+\sigma_{BT}^2 \right)\chi_{n-1}^2(\delta_2) \quad \delta_2 = 0$$

$$Y'A_3Y \sim \sigma_{BT}^2 \chi_{1}^2(\delta_3) \quad \delta_3 = \frac{n(\mu_1-\mu_2)^2}{2\sigma_{BT}^2}$$

$$Y'A_4Y \sim \sigma_{BT}^2 \chi_{n-1}^2(\delta_4) \quad \delta_4 = 0$$

### d

If a random variable $X$ has $\chi^2$ distribution with $d$ degrees of freedom and noncentrality $\delta$, $\text{E}(cX) = cd + \delta$ for some constant $c$. 

$$\text{E}(Y'A_1Y) = \left(\frac{\sigma_B^2}{2}+\sigma_{BT}^2 \right) + \frac{n(\mu_1+\mu_2)^2}{\sigma_B^2 + 2\sigma_{BT}^2}$$

$$\text{E}(Y'A_2Y) = \left(\frac{\sigma_B^2}{2}+\sigma_{BT}^2 \right)(n-1)$$

$$\text{E}(Y'A_3Y) = \sigma_{BT}^2 + \frac{n(\mu_1-\mu_2)^2}{2\sigma_{BT}^2}$$


$$\text{E}(Y'A_4Y) = \sigma_{BT}^2(n-1)$$


$$\text{E}\left( \sum_{i}\sum_{j}Y_{ij}^2 \right)= \sum_{k=1}^4 \text{E}(Y'A_iY) = n\left(\frac{\sigma_B^2}{2}+\sigma_{BT}^2 \right) + n\left[\frac{(\mu_1+\mu_2)^2}{\sigma_B^2 + 2\sigma_{BT}^2} + \frac{(\mu_1-\mu_2)^2}{2\sigma_{BT}^2} \right]$$







